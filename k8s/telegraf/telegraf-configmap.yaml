apiVersion: v1
kind: ConfigMap
metadata:
  name: telegraf-config
  namespace: ibuki-mitarashi-bot
data:
  telegraf.conf: |-
    ########################################
    # Global Agent Configuration
    ########################################
    [agent]
      interval = "10s"
      round_interval = true
      metric_batch_size = 1000
      metric_buffer_limit = 10000
      collection_jitter = "0s"
      flush_interval = "10s"
      flush_jitter = "0s"
      precision = "1ns"

    ########################################
    # OUTPUTS
    ########################################
    [[outputs.influxdb_v2]]
      ## InfluxDB v2 details - configure via env vars in DaemonSet
      ## URL example: https://influxdb.skyia.jp
      urls = ["${INFLUX_URL}"]
      token = "${INFLUX_TOKEN}"
      organization = "${INFLUX_ORG}"
      bucket = "${INFLUX_BUCKET}"

    ########################################
    # INPUTS - system, cpu, mem, disk, processes
    ########################################
    [[inputs.cpu]]
      percpu = true
      totalcpu = true
      collect_cpu_time = false

    [[inputs.mem]]

    [[inputs.disk]]
      ignore_fs = ["tmpfs", "devtmpfs"]

    [[inputs.kernel]]

    [[inputs.processes]]

    [[inputs.net]]

    # kubernetes inputs - requires RBAC to list pods/nodes
    [[inputs.kubernetes]]
      url = ""
      response_timeout = "5s"
      tls_ca = ""

    # docker/container metrics (if node has docker socket)
    [[inputs.docker]]
      endpoint = "unix:///var/run/docker.sock"
      gather_services = false

    ########################################
    # LOGS - tail container logs produced by kubelet
    ########################################
    [[inputs.tail]]
      files = ["/var/log/containers/*.log"]
      from_beginning = false
      name_override = "k8s_container_logs"
      data_format = "json"
      json_time_key = "time"
      json_time_format = "RFC3339"
      # If your logs are NOT JSON, change data_format to "grok" and set
      # grok_patterns appropriately. When using json, do not set grok_patterns/grok_names.

    ########################################
    # PROCESSOR/AGGREGATOR examples (optional)
    ########################################
    # NOTE: The 'decode_json_fields' processor may not be available in all
    # telegraf builds. If it's missing the agent will fail to start (undefined
    # processor). Removed here to ensure config loads. If you need to decode a
    # nested JSON string (for example container log stored under 'log' or
    # 'message'), consider one of:
    #  - use data_format = "grok" and then a parser to decode JSON
    #  - use an image/build of telegraf that includes 'processors.decode_json_fields'
    #  - use processors.parser (if available) to parse the nested field

    [[processors.rename]]
      [[processors.rename.replace]]
        field = "usage_guest"
        dest = "cpu_usage_guest"
